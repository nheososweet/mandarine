import os
import json
import logging
import httpx
from typing import List, Dict, Any, Optional

# Import highlighter m·ªõi
from app.services.rag.lightrag_highlighter import LightRAGHighlighter

logger = logging.getLogger(__name__)

# --- C·∫§U H√åNH (HARDCODED) ---
LIGHTRAG_API_URL = "http://localhost:9621"
# URL ƒë·ªÉ FE t·∫£i file PDF
STATIC_FILE_URL_PREFIX = "http://localhost:8000/static/uploads" 
# ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ch·ª©a file PDF g·ªëc tr√™n ·ªï ƒëƒ©a
UPLOAD_DIR = os.getenv("UPLOAD_DIR", "uploads")
class LightRAGBridgeService:
    def __init__(self):
        self.client = httpx.AsyncClient(timeout=60.0)

    async def get_references_with_highlights(
        self, payload: Dict[str, Any], request=None
    ) -> Dict[str, Any]:
        """
        1. G·ªçi LightRAG API l·∫•y chunks
        2. D√πng LightRAGHighlighter (Skeleton Match) ƒë·ªÉ t√¨m t·ªça ƒë·ªô
        3. Tr·∫£ v·ªÅ format chu·∫©n cho Frontend
        """
        
        # --- B∆Ø·ªöC 1: G·ªçi LightRAG API (t·∫Øt stream) ---
        lightrag_payload = payload.copy()
        lightrag_payload["stream"] = False

        try:
            response = await self.client.post(
                f"{LIGHTRAG_API_URL}/query/data",
                json=lightrag_payload
            )
            response.raise_for_status()
            rag_data = response.json()
        except Exception as e:
            logger.error(f"‚ùå LightRAG API Error: {e}")
            return {
                "status": "error", 
                "sources": [], 
                "highlights": {}, 
                "raw_chunks": [], 
                "error": str(e)
            }

        # Ki·ªÉm tra d·ªØ li·ªáu tr·∫£ v·ªÅ
        chunks_list = rag_data.get("data", {}).get("chunks", [])
        if not chunks_list:
            return {
                "status": "success", 
                "sources": [], 
                "highlights": {}, 
                "raw_chunks": [],
                "entities": rag_data.get("data", {}).get("entities", []),
                "relationships": rag_data.get("data", {}).get("relationships", [])
            }

        # --- B∆Ø·ªöC 2: Gom nh√≥m Chunks theo File ---
        chunks_by_file = {}
        for chunk in chunks_list:
            raw_path = chunk.get("file_path", "")
            if not raw_path: continue
            
            # L·∫•y t√™n file (VD: noiquy.pdf)
            base_name = os.path.basename(raw_path)
            
            if base_name not in chunks_by_file:
                chunks_by_file[base_name] = []
            
            # Gi·ªØ nguy√™n chunk data cho highlighter
            chunks_by_file[base_name].append(chunk)

        # --- B∆Ø·ªöC 3: X·ª≠ l√Ω t·ª´ng file ---
        final_highlights_map = {}
        sources_list = []
        raw_chunks_list = []
        
        # S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë√£ hardcode
        abs_upload_dir = os.path.abspath(UPLOAD_DIR)

        for file_name, chunks in chunks_by_file.items():
            # 1. URL cho Frontend (S·ª≠ d·ª•ng URL hardcode + t√™n file)
            # V√≠ d·ª•: http://localhost:8000/static/uploads/noiquy.pdf
            # L∆∞u √Ω: Logic FE c·ªßa b·∫°n c√≥ th·ªÉ c·∫ßn URL ch√≠nh x√°c ƒë·ªÉ map key trong highlight
            file_url = f"/noiquy.pdf" # DEMO fix c·ª©ng theo format b·∫°n g·ª≠i trong prompt tr∆∞·ªõc
            # N·∫øu mu·ªën dynamic: file_url = f"{STATIC_FILE_URL_PREFIX}/{file_name}"
            
            # 2. Path v·∫≠t l√Ω ƒë·ªÉ ƒë·ªçc PDF
            real_pdf_path = os.path.join(abs_upload_dir, file_name)
            
            chunk_page_map = {} # Map chunk_id -> page index (ƒë·ªÉ scroll t·ªõi)

            # --- A. X·ª¨ L√ù HIGHLIGHT ---
            if file_name.lower().endswith('.pdf') and os.path.exists(real_pdf_path):
                try:
                    logger.info(f"üîÜ Extracting highlights for {file_name} using Skeleton Match...")
                    
                    # KH·ªûI T·∫†O HIGHLIGHTER
                    with LightRAGHighlighter(real_pdf_path) as highlighter:
                        # G·ªçi h√†m t√¨m ki·∫øm
                        chunk_highlights = highlighter.find_all_highlights(chunks)
                        
                        file_areas_flat = []
                        for ch in chunk_highlights:
                            # L∆∞u page t√¨m ƒë∆∞·ª£c cho chunk n√†y (ƒë·ªÉ d√πng cho raw chunk v√† source)
                            # pageIndex c·ªßa th∆∞ vi·ªán l√† 0-based, ta l∆∞u +1 cho d·ªÖ ƒë·ªçc n·∫øu c·∫ßn, 
                            # nh∆∞ng FE th∆∞·ªùng d√πng 0-based cho highlight, 1-based cho hi·ªÉn th·ªã text.
                            chunk_page_map[ch.chunkId] = ch.pageIndex + 1 
                            
                            for area in ch.areas:
                                file_areas_flat.append({
                                    "pageIndex": area.pageIndex,
                                    "left": round(area.left, 2),
                                    "top": round(area.top, 2),
                                    "width": round(area.width, 2),
                                    "height": round(area.height, 2),
                                    "chunkId": ch.chunkId 
                                })
                        
                        if file_areas_flat:
                            # Key c·ªßa highlights map ph·∫£i kh·ªõp v·ªõi url trong source
                            final_highlights_map[file_url] = file_areas_flat
                            logger.info(f"   ‚úÖ Found {len(file_areas_flat)} areas")
                        else:
                            logger.warning(f"   ‚ö†Ô∏è No highlights found")
                            
                except Exception as e:
                    logger.error(f"‚ùå Error highlighting {file_name}: {e}")
            else:
                if not os.path.exists(real_pdf_path):
                    logger.error(f"‚ùå File not found at: {real_pdf_path}")
            
            # --- B. T·∫†O SOURCES LIST & RAW CHUNKS ---
            # T√¨m page m·∫∑c ƒë·ªãnh (min page t√¨m th·∫•y ho·∫∑c 1)
            default_page = 1
            if chunk_page_map:
                default_page = min(chunk_page_map.values())
            
            sources_list.append({
                "source": file_name,
                "url": file_url,
                "page": default_page
            })

            for chunk in chunks:
                c_id = chunk.get("chunk_id", "unknown")
                raw_chunks_list.append({
                    "id": c_id,
                    "text": chunk.get("content", ""),
                    "source": file_name,
                    "url": file_url,
                    # N·∫øu t√¨m th·∫•y highlight th√¨ l·∫•y page ƒë√≥, ko th√¨ page 0
                    "page": chunk_page_map.get(c_id, 0) 
                })

        return {
            "status": "success",
            "sources": sources_list,
            "highlights": final_highlights_map,
            "raw_chunks": raw_chunks_list,
            "entities": rag_data.get("data", {}).get("entities", []),
            "relationships": rag_data.get("data", {}).get("relationships", [])
        }

    async def close(self):
        await self.client.aclose()

lightrag_bridge_service = LightRAGBridgeService()